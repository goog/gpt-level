# Some experiences of using ChatGPT

I have read HN everyday. I'm sure GPT or LLM is the big hit in technology this year(2023). many works or software are focused on gpt-4, LLaMA, stanford alpaca and Stanford AI research. some LLMs can run on a PC is a good news for individuals.

# Personal experience

i started to use ChatGPT from 7 Feb 2023. i subscribed ChatGPT Plus on April 27
it's almost four months I have used ChatGPT.  
it is just a machine without a bias or opinion about some political questions, or say it outputs without emotion. the speak style is not like man.
# ChatGPT practice
prompt starts with some keyword like **write, summarize and complete**   
prompt with simple and detailed words to express your need,
if does not work well then retry by modifying prompt and add a little more information related that should be added.
in some degree like you are constructing or making up a summary for one post you want to find out from the huge digit world.
Because more lucky and possible to get a good respond if there is more context information.  
[best practices for prompt enginneering](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api)
## As a programmer, what can it do for you?

it is usable, so you can always ask him some question as if it is an advanced programmer or library assistant!
it could give you a good answer for short session question.
i often ask some questions about C programming, JSON data handle, SQLite and some python code generate.
although some official data suggests it is good at JavaScript and python, but i find it also good at SQL like SQLite or JSON data process.
it indeed helped me finish some works include below

1. SQLite Table Migration from a file to another
2. JSON data parse or construct in C when have sample data
3. generate a string buffer module see [stringbuffer](https://github.com/goog/stringbuffer)
4. show me some code examples in chat mode, so i dont need to google it or see some API document. if ~~the respond is correct and short~~, so it may save you some time compared to read one long and full post or document in the case. if time enough, the latter is better.

## issues

1 reasoning limit  
I doubt it has any reasoning ability or it just generates some texts by context or similar embedding array  
i asked it a very hard linux version change question:  
![enter image description here](https://i.ibb.co/t2BhMw5/x-20230528064051.png)
2 Sometimes hallucinations
once about using jshn library on openWrt, it gave me does not exist shell function. 
3 the subscription is complicated to pay off for some country 


## advantages to google
it is in chat mode, which is a natural interactive mode like you are speaking to a person.
you can ask many questions in one chat session(only on a UI page) and get one answer. To get only one perfect answer is our ideal dream to acquire knowledge.
it is amazing to get answers for questions like how to make/chose something because those answers are artificially crafted answers. it is more like a good knowledge database than a GPT. you should be shocked by it's knowledge at first time. 
you can think it as an advanced context based search engine.
## thinking

1. safe
2. how does gpt reason? 
3. embedding

i can't ask gpt to tell me how to make a gun.
i don't understand how gpt do the reasoning. there is some algorithm like CoT or ToT. but it's not related to gpt theory because GPT is **not that a reasoning framework**.
why a sentence is a 1500-dimensional embedding vector? some like max polling for CNN, so someone say information is compressed by LLM. all digit knowledge documents come into a large model? maybe depends on database??

more read:
[Democratizing AI with open-source language models](https://lwn.net/Articles/931853/)
[gpt level define](https://github.com/goog/gpt-level)



> **ProTip:** the post is only personal opinion.




